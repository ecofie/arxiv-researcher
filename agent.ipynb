{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "We are now going to build the Agent\n",
    "first,we load the index using the storage context and the load_index_from_storage function\n",
    "'''\n",
    "\n",
    "from llama_index.core import StorageContext,load_index_from_storage\n",
    "from constant import embed_model\n",
    "\n",
    "#load the index from the storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir='index/')\n",
    "index = load_index_from_storage(storage_context,embed_model=embed_model) #we parse the storage context through the load_index_from_storage function and the embed_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the RAG tool\n",
    "This is the tool the agent will use to fetch information from the existing database\n",
    "'''\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from constant import llm_model\n",
    "\n",
    "\n",
    "#load the llm model engine\n",
    "query_engine= index.as_query_engine(llm_model=llm_model, similarity_top_k=4) #we find 5 max similarity vectors when the query is submitted\n",
    "\n",
    "#the tool the engine will use to fetch information\n",
    "rag_tool=QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name = \"research_paper_query_engine_tool\",\n",
    "    description = \"A RAG engine with recent Research paper\",\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function to display the prompt\n",
    "from IPython.display import Markdown,display\n",
    "\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for key, prompt in prompts_dict.items():\n",
    "        display(Markdown(f\"**Prompt key**: {key}\"))\n",
    "        print(prompt.get_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt key**: response_synthesizer:text_qa_template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt key**: response_synthesizer:refine_template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    }
   ],
   "source": [
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the other tools the agent will use\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from tools import download_pdf, fetch_arxiv_papers\n",
    "\n",
    "download_pdf_tool = FunctionTool.from_defaults(\n",
    "    download_pdf, \n",
    "    name=\"download_pdf_file_tool\", \n",
    "    description=\"pyhton function that downloads a pdfs file by link\",\n",
    "    )\n",
    "\n",
    "fetch_arxiv_tool = FunctionTool.from_defaults(\n",
    "    fetch_arxiv_papers, \n",
    "    name=\"fetch_from_arxiv\", \n",
    "    description=\"download the {max_result} recent papers regarding the topic {title} from arvix\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the Agent(We use the ReAct beacuse the agent will be able to react to the user input)\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    [download_pdf_tool,rag_tool,fetch_arxiv_tool],llm=llm_model,verbose=True\n",
    ")   #parse the list of tools the agent will use and the llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "to be able to chat with the agent,we need a query template\n",
    "'''\n",
    "query_template = ''' I am interested in {topic}.\n",
    "Find papers in your knowledge base that are related to topic.\n",
    "Use the following template to query research_paper_query_engine_tool tool:Provide title, summary, authors and links to download to papers related to {topic}.\n",
    "if there are not,could you search the recent one from arxiv\n",
    "IMPORTANT :do not download papers unless the user asks for it explicitly.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step eb620a0a-fb8b-4e9c-87af-3a9e735ddd45. Step input:  I am interested in Multi-modal models.\n",
      "Find papers in your knowledge base that are related to topic.\n",
      "Use the following template to query research_paper_query_engine_tool tool:Provide title, summary, authors and links to download to pappers related to Multi-modal models.\n",
      "if there are not,could you search the recent one from arxiv\n",
      "IMPORTANT :do not download papers unless the user asks for it explicitly.\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me find research papers related to Multi-modal models.\n",
      "Action: research_paper_query_engine_tool\n",
      "Action Input: {'input': 'Multi-modal models'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Context information is below.\n",
      "---------------------\n",
      "Title: Distilling Multi-modal Large Language Models for Autonomous Driving\n",
      "Authors: Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli, Vishal M. Patel, Fatih Porikli\n",
      "summary: Autonomous driving demands safe motion planning, especially in critical\n",
      "\"long-tail\" scenarios. Recent end-to-end autonomous driving systems leverage\n",
      "large language models (LLMs) as planners to improve generalizability to rare\n",
      "events. However, using LLMs at test time introduces high computational costs.\n",
      "To address this, we propose DiMA, an end-to-end autonomous driving system that\n",
      "maintains the efficiency of an LLM-free (or vision-based) planner while\n",
      "leveraging the world knowledge of an LLM. DiMA distills the information from a\n",
      "multi-modal LLM to a vision-based end-to-end planner through a set of specially\n",
      "designed surrogate tasks. Under a joint training strategy, a scene encoder\n",
      "common to both networks produces structured representations that are\n",
      "semantically grounded as well as aligned to the final planning objective.\n",
      "Notably, the LLM is optional at inference, enabling robust planning without\n",
      "compromising on efficiency. Training with DiMA results in a 37% reduction in\n",
      "the L2 trajectory error and an 80% reduction in the collision rate of the\n",
      "vision-based planner, as well as a 44% trajectory error reduction in longtail\n",
      "scenarios. DiMA also achieves state-of-the-art performance on the nuScenes\n",
      "planning benchmark.\n",
      "Published: 2025-01-16 18:59:53+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CV\n",
      "categories: cs.CV, cs.RO\n",
      "PDF url: http://arxiv.org/pdf/2501.09757v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09757v1\n",
      "\n",
      "Title: A Simple Aerial Detection Baseline of Multimodal Language Models\n",
      "Authors: Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang\n",
      "summary: The multimodal language models (MLMs) based on generative pre-trained\n",
      "Transformer are considered powerful candidates for unifying various domains and\n",
      "tasks. MLMs developed for remote sensing (RS) have demonstrated outstanding\n",
      "performance in multiple tasks, such as visual question answering and visual\n",
      "grounding. In addition to visual grounding that detects specific objects\n",
      "corresponded to given instruction, aerial detection, which detects all objects\n",
      "of multiple categories, is also a valuable and challenging task for RS\n",
      "foundation models. However, aerial detection has not been explored by existing\n",
      "RS MLMs because the autoregressive prediction mechanism of MLMs differs\n",
      "significantly from the detection outputs. In this paper, we present a simple\n",
      "baseline for applying MLMs to aerial detection for the first time, named\n",
      "LMMRotate. Specifically, we first introduce a normalization method to transform\n",
      "detection outputs into textual outputs to be compatible with the MLM framework.\n",
      "Then, we propose a evaluation method, which ensures a fair comparison between\n",
      "MLMs and conventional object detection models. We construct the baseline by\n",
      "fine-tuning open-source general-purpose MLMs and achieve impressive detection\n",
      "performance comparable to conventional detector. We hope that this baseline\n",
      "will serve as a reference for future MLM development, enabling more\n",
      "comprehensive capabilities for understanding RS images. Code is available at\n",
      "https://github.com/Li-Qingyun/mllm-mmrotate.\n",
      "Published: 2025-01-16 18:09:22+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CV\n",
      "categories: cs.CV, cs.AI\n",
      "PDF url: http://arxiv.org/pdf/2501.09720v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09720v1\n",
      "\n",
      "Title: Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\n",
      "Authors: Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, Saining Xie\n",
      "summary: Generative models have made significant impacts across various domains,\n",
      "largely due to their ability to scale during training by increasing data,\n",
      "computational resources, and model size, a phenomenon characterized by the\n",
      "scaling laws. Recent research has begun to explore inference-time scaling\n",
      "behavior in Large Language Models (LLMs), revealing how performance can further\n",
      "improve with additional computation during inference. Unlike LLMs, diffusion\n",
      "models inherently possess the flexibility to adjust inference-time computation\n",
      "via the number of denoising steps, although the performance gains typically\n",
      "flatten after a few dozen. In this work, we explore the inference-time scaling\n",
      "behavior of diffusion models beyond increasing denoising steps and investigate\n",
      "how the generation performance can further improve with increased computation.\n",
      "Specifically, we consider a search problem aimed at identifying better noises\n",
      "for the diffusion sampling process. We structure the design space along two\n",
      "axes: the verifiers used to provide feedback, and the algorithms used to find\n",
      "better noise candidates. Through extensive experiments on class-conditioned and\n",
      "text-conditioned image generation benchmarks, our findings reveal that\n",
      "increasing inference-time compute leads to substantial improvements in the\n",
      "quality of samples generated by diffusion models, and with the complicated\n",
      "nature of images, combinations of the components in the framework can be\n",
      "specifically chosen to conform with different application scenario.\n",
      "Published: 2025-01-16 18:30:37+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CV\n",
      "categories: cs.CV\n",
      "PDF url: http://arxiv.org/pdf/2501.09732v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09732v1\n",
      "\n",
      "Title: Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key\n",
      "Authors: Zhihe Yang, Xufang Luo, Dongqi Han, Yunjian Xu, Dongsheng Li\n",
      "summary: Hallucination remains a major challenge for Large Vision-Language Models\n",
      "(LVLMs). Direct Preference Optimization (DPO) has gained increasing attention\n",
      "as a simple solution to hallucination issues. It directly learns from\n",
      "constructed preference pairs that reflect the severity of hallucinations in\n",
      "responses to the same prompt and image. Nonetheless, different data\n",
      "construction methods in existing works bring notable performance variations. We\n",
      "identify a crucial factor here: outcomes are largely contingent on whether the\n",
      "constructed data aligns on-policy w.r.t the initial (reference) policy of DPO.\n",
      "Theoretical analysis suggests that learning from off-policy data is impeded by\n",
      "the presence of KL-divergence between the updated policy and the reference\n",
      "policy. From the perspective of dataset distribution, we systematically\n",
      "summarize the inherent flaws in existing algorithms that employ DPO to address\n",
      "hallucination issues. To alleviate the problems, we propose On-Policy Alignment\n",
      "(OPA)-DPO framework, which uniquely leverages expert feedback to correct\n",
      "hallucinated responses and aligns both the original and expert-revised\n",
      "responses in an on-policy manner. Notably, with only 4.8k data, OPA-DPO\n",
      "achieves an additional reduction in the hallucination rate of LLaVA-1.5-7B:\n",
      "13.26% on the AMBER benchmark and 5.39% on the Object-Hal benchmark, compared\n",
      "to the previous SOTA algorithm trained with 16k samples.\n",
      "Published: 2025-01-16 17:48:03+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CV\n",
      "categories: cs.CV\n",
      "PDF url: http://arxiv.org/pdf/2501.09695v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09695v1\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Multi-modal models\n",
      "Answer: \n",
      "\u001b[0m> Running step 6c4dc4c5-d50a-4b49-afea-39e32e41db4e. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Here are some recent papers related to Multi-modal models:\n",
      "\n",
      "1. **Title**: Distilling Multi-modal Large Language Models for Autonomous Driving  \n",
      "   **Authors**: Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli, Vishal M. Patel, Fatih Porikli  \n",
      "   **Summary**: This paper proposes DiMA, an end-to-end autonomous driving system that distills information from a multi-modal large language model (LLM) to a vision-based planner, improving efficiency and reducing trajectory errors.  \n",
      "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09757v1) | [arXiv Link](http://arxiv.org/abs/2501.09757v1)\n",
      "\n",
      "2. **Title**: A Simple Aerial Detection Baseline of Multimodal Language Models  \n",
      "   **Authors**: Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang  \n",
      "   **Summary**: This paper presents a baseline for applying multimodal language models (MLMs) to aerial detection in remote sensing, achieving impressive detection performance comparable to conventional models.  \n",
      "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09720v1) | [arXiv Link](http://arxiv.org/abs/2501.09720v1)\n",
      "\n",
      "3. **Title**: Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps  \n",
      "   **Authors**: Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, Saining Xie  \n",
      "   **Summary**: This work explores the inference-time scaling behavior of diffusion models, revealing how performance can improve with increased computation during inference.  \n",
      "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09732v1) | [arXiv Link](http://arxiv.org/abs/2501.09732v1)\n",
      "\n",
      "4. **Title**: Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key  \n",
      "   **Authors**: Zhihe Yang, Xufang Luo, Dongqi Han, Yunjian Xu, Dongsheng Li  \n",
      "   **Summary**: This paper addresses hallucination issues in large vision-language models using Direct Preference Optimization (DPO) and proposes an On-Policy Alignment framework to improve response accuracy.  \n",
      "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09695v1) | [arXiv Link](http://arxiv.org/abs/2501.09695v1)\n",
      "\n",
      "These papers provide insights into various aspects of multi-modal models and their applications.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "answer = agent.chat(query_template.format(topic= \"Multi-modal models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some recent papers related to Multi-modal models:\n",
       "\n",
       "1. **Title**: Distilling Multi-modal Large Language Models for Autonomous Driving  \n",
       "   **Authors**: Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli, Vishal M. Patel, Fatih Porikli  \n",
       "   **Summary**: This paper proposes DiMA, an end-to-end autonomous driving system that distills information from a multi-modal large language model (LLM) to a vision-based planner, improving efficiency and reducing trajectory errors.  \n",
       "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09757v1) | [arXiv Link](http://arxiv.org/abs/2501.09757v1)\n",
       "\n",
       "2. **Title**: A Simple Aerial Detection Baseline of Multimodal Language Models  \n",
       "   **Authors**: Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang  \n",
       "   **Summary**: This paper presents a baseline for applying multimodal language models (MLMs) to aerial detection in remote sensing, achieving impressive detection performance comparable to conventional models.  \n",
       "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09720v1) | [arXiv Link](http://arxiv.org/abs/2501.09720v1)\n",
       "\n",
       "3. **Title**: Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps  \n",
       "   **Authors**: Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, Saining Xie  \n",
       "   **Summary**: This work explores the inference-time scaling behavior of diffusion models, revealing how performance can improve with increased computation during inference.  \n",
       "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09732v1) | [arXiv Link](http://arxiv.org/abs/2501.09732v1)\n",
       "\n",
       "4. **Title**: Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key  \n",
       "   **Authors**: Zhihe Yang, Xufang Luo, Dongqi Han, Yunjian Xu, Dongsheng Li  \n",
       "   **Summary**: This paper addresses hallucination issues in large vision-language models using Direct Preference Optimization (DPO) and proposes an On-Policy Alignment framework to improve response accuracy.  \n",
       "   **Link**: [Download PDF](http://arxiv.org/pdf/2501.09695v1) | [arXiv Link](http://arxiv.org/abs/2501.09695v1)\n",
       "\n",
       "These papers provide insights into various aspects of multi-modal models and their applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to better visualize the answer,we use the display function\n",
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 0ae0bece-75ef-48f7-bc51-a3076a19eaf0. Step input:  download the following papers:\n",
      "for each paper:\n",
      "1. Process one paper at a time\n",
      "2. state which paper number you are processing of the total\n",
      "3.complete a full download cycle before moving to the next one\n",
      "4.explicitly state when moving to the next one\n",
      "5.provide a final summary only after all papers are downloaded\n",
      "\u001b[1;3;38;5;200mThought: I will start downloading the papers one at a time, as requested. I will begin with the first paper.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2501.09757v1', 'output_file_name': 'Distilling_Multi-modal_Large_Language_Models_for_Autonomous_Driving.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF file downloaded successfully to papers\\Distilling_Multi-modal_Large_Language_Models_for_Autonomous_Driving.pdf\n",
      "\u001b[0m> Running step 6f37eb42-65a5-4237-a4df-0211ceed86ec. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have completed the download of the first paper. Now I will proceed to download the second paper.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2501.09720v1', 'output_file_name': 'A_Simple_Aerial_Detection_Baseline_of_Multimodal_Language_Models.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF file downloaded successfully to papers\\A_Simple_Aerial_Detection_Baseline_of_Multimodal_Language_Models.pdf\n",
      "\u001b[0m> Running step 326f223a-b1d1-44a9-91c3-817530926793. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have completed the download of the second paper. Now I will proceed to download the third paper.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2501.09732v1', 'output_file_name': 'Inference_Time_Scaling_for_Diffusion_Models_beyond_Scaling_Denoising_Steps.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF file downloaded successfully to papers\\Inference_Time_Scaling_for_Diffusion_Models_beyond_Scaling_Denoising_Steps.pdf\n",
      "\u001b[0m> Running step e7a41ab1-a697-468f-8676-c287c49b21eb. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have completed the download of the third paper. Now I will proceed to download the fourth paper.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2501.09695v1', 'output_file_name': 'Mitigating_Hallucinations_in_Large_Vision_Language_Models_via_DPO.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF file downloaded successfully to papers\\Mitigating_Hallucinations_in_Large_Vision_Language_Models_via_DPO.pdf\n",
      "\u001b[0m> Running step ac4e3efb-59e7-4274-b09c-4cd6d65789a5. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have completed the download of all four papers. Now I will provide a final summary of the downloaded papers.\n",
      "Answer: 1. **Distilling Multi-modal Large Language Models for Autonomous Driving**  \n",
      "   - Authors: Deepti Hegde et al.  \n",
      "   - Summary: Proposes DiMA, an end-to-end autonomous driving system that distills information from a multi-modal large language model (LLM) to a vision-based planner, improving efficiency and reducing trajectory errors.  \n",
      "\n",
      "2. **A Simple Aerial Detection Baseline of Multimodal Language Models**  \n",
      "   - Authors: Qingyun Li et al.  \n",
      "   - Summary: Presents a baseline for applying multimodal language models (MLMs) to aerial detection in remote sensing, achieving impressive detection performance comparable to conventional models.  \n",
      "\n",
      "3. **Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps**  \n",
      "   - Authors: Nanye Ma et al.  \n",
      "   - Summary: Explores the inference-time scaling behavior of diffusion models, revealing how performance can improve with increased computation during inference.  \n",
      "\n",
      "4. **Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key**  \n",
      "   - Authors: Zhihe Yang et al.  \n",
      "   - Summary: Addresses hallucination issues in large vision-language models using Direct Preference Optimization (DPO) and proposes an On-Policy Alignment framework to improve response accuracy.  \n",
      "\n",
      "All papers have been successfully downloaded and are available for review.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#since the agent retains memory,we can use the same query template to ask for the agnet to download the papers.\n",
    "answer = agent.chat(''' download the following papers:\n",
    "for each paper:\n",
    "1. Process one paper at a time\n",
    "2. state which paper number you are processing of the total\n",
    "3.complete a full download cycle before moving to the next one\n",
    "4.explicitly state when moving to the next one\n",
    "5.provide a final summary only after all papers are downloaded''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. **Distilling Multi-modal Large Language Models for Autonomous Driving**  \n",
       "   - Authors: Deepti Hegde et al.  \n",
       "   - Summary: Proposes DiMA, an end-to-end autonomous driving system that distills information from a multi-modal large language model (LLM) to a vision-based planner, improving efficiency and reducing trajectory errors.  \n",
       "\n",
       "2. **A Simple Aerial Detection Baseline of Multimodal Language Models**  \n",
       "   - Authors: Qingyun Li et al.  \n",
       "   - Summary: Presents a baseline for applying multimodal language models (MLMs) to aerial detection in remote sensing, achieving impressive detection performance comparable to conventional models.  \n",
       "\n",
       "3. **Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps**  \n",
       "   - Authors: Nanye Ma et al.  \n",
       "   - Summary: Explores the inference-time scaling behavior of diffusion models, revealing how performance can improve with increased computation during inference.  \n",
       "\n",
       "4. **Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key**  \n",
       "   - Authors: Zhihe Yang et al.  \n",
       "   - Summary: Addresses hallucination issues in large vision-language models using Direct Preference Optimization (DPO) and proposes an On-Policy Alignment framework to improve response accuracy.  \n",
       "\n",
       "All papers have been successfully downloaded and are available for review."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 80fb732e-df12-479a-8fd5-97aa593c1a35. Step input:  I am interested in Quantum Computing.\n",
      "Find papers in your knowledge base that are related to topic.\n",
      "Use the following template to query research_paper_query_engine_tool tool:Provide title, summary, authors and links to download to pappers related to Quantum Computing.\n",
      "if there are not,could you search the recent one from arxiv\n",
      "IMPORTANT :do not download papers unless the user asks for it explicitly.\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to find research papers related to Quantum Computing.\n",
      "Action: research_paper_query_engine_tool\n",
      "Action Input: {'input': 'Quantum Computing'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Context information is below.\n",
      "---------------------\n",
      "Title: Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\n",
      "Authors: Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, Saining Xie\n",
      "summary: Generative models have made significant impacts across various domains,\n",
      "largely due to their ability to scale during training by increasing data,\n",
      "computational resources, and model size, a phenomenon characterized by the\n",
      "scaling laws. Recent research has begun to explore inference-time scaling\n",
      "behavior in Large Language Models (LLMs), revealing how performance can further\n",
      "improve with additional computation during inference. Unlike LLMs, diffusion\n",
      "models inherently possess the flexibility to adjust inference-time computation\n",
      "via the number of denoising steps, although the performance gains typically\n",
      "flatten after a few dozen. In this work, we explore the inference-time scaling\n",
      "behavior of diffusion models beyond increasing denoising steps and investigate\n",
      "how the generation performance can further improve with increased computation.\n",
      "Specifically, we consider a search problem aimed at identifying better noises\n",
      "for the diffusion sampling process. We structure the design space along two\n",
      "axes: the verifiers used to provide feedback, and the algorithms used to find\n",
      "better noise candidates. Through extensive experiments on class-conditioned and\n",
      "text-conditioned image generation benchmarks, our findings reveal that\n",
      "increasing inference-time compute leads to substantial improvements in the\n",
      "quality of samples generated by diffusion models, and with the complicated\n",
      "nature of images, combinations of the components in the framework can be\n",
      "specifically chosen to conform with different application scenario.\n",
      "Published: 2025-01-16 18:30:37+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CV\n",
      "categories: cs.CV\n",
      "PDF url: http://arxiv.org/pdf/2501.09732v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09732v1\n",
      "\n",
      "Title: CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education\n",
      "Authors: Tianyu Wang, Nianjun Zhou, Zhixiong Chen\n",
      "summary: Many non-traditional students in cybersecurity programs often lack access to\n",
      "advice from peers, family members and professors, which can hinder their\n",
      "educational experiences. Additionally, these students may not fully benefit\n",
      "from various LLM-powered AI assistants due to issues like content relevance,\n",
      "locality of advice, minimum expertise, and timing. This paper addresses these\n",
      "challenges by introducing an application designed to provide comprehensive\n",
      "support by answering questions related to knowledge, skills, and career\n",
      "preparation advice tailored to the needs of these students. We developed a\n",
      "learning tool platform, CyberMentor, to address the diverse needs and pain\n",
      "points of students majoring in cybersecurity. Powered by agentic workflow and\n",
      "Generative Large Language Models (LLMs), the platform leverages\n",
      "Retrieval-Augmented Generation (RAG) for accurate and contextually relevant\n",
      "information retrieval to achieve accessibility and personalization. We\n",
      "demonstrated its value in addressing knowledge requirements for cybersecurity\n",
      "education and for career marketability, in tackling skill requirements for\n",
      "analytical and programming assignments, and in delivering real time on demand\n",
      "learning support. Using three use scenarios, we showcased CyberMentor in\n",
      "facilitating knowledge acquisition and career preparation and providing\n",
      "seamless skill-based guidance and support. We also employed the LangChain\n",
      "prompt-based evaluation methodology to evaluate the platform's impact,\n",
      "confirming its strong performance in helpfulness, correctness, and\n",
      "completeness. These results underscore the system's ability to support students\n",
      "in developing practical cybersecurity skills while improving equity and\n",
      "sustainability within higher education. Furthermore, CyberMentor's open-source\n",
      "design allows for adaptation across other disciplines, fostering educational\n",
      "innovation and broadening its potential impact.\n",
      "Published: 2025-01-16 18:00:06+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CY\n",
      "categories: cs.CY, cs.AI, K.3.2; I.2.1\n",
      "PDF url: http://arxiv.org/pdf/2501.09709v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09709v1\n",
      "\n",
      "Title: OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking\n",
      "Authors: Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, Huajun Chen\n",
      "summary: Machine writing with large language models often relies on\n",
      "retrieval-augmented generation. However, these approaches remain confined\n",
      "within the boundaries of the model's predefined scope, limiting the generation\n",
      "of content with rich information. Specifically, vanilla-retrieved information\n",
      "tends to lack depth, utility, and suffers from redundancy, which negatively\n",
      "impacts the quality of generated articles, leading to shallow, repetitive, and\n",
      "unoriginal outputs. To address these issues, we propose OmniThink, a machine\n",
      "writing framework that emulates the human-like process of iterative expansion\n",
      "and reflection. The core idea behind OmniThink is to simulate the cognitive\n",
      "behavior of learners as they progressively deepen their knowledge of the\n",
      "topics. Experimental results demonstrate that OmniThink improves the knowledge\n",
      "density of generated articles without compromising metrics such as coherence\n",
      "and depth. Human evaluations and expert feedback further highlight the\n",
      "potential of OmniThink to address real-world challenges in the generation of\n",
      "long-form articles.\n",
      "Published: 2025-01-16 18:58:06+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.CL\n",
      "categories: cs.CL\n",
      "PDF url: http://arxiv.org/pdf/2501.09751v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09751v1\n",
      "\n",
      "Title: Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models\n",
      "Authors: Bihui Jin, Jiayue Wang, Pengyu Nie\n",
      "summary: Machine learning developers frequently use interactive computational\n",
      "notebooks, such as Jupyter notebooks, to host code for data processing and\n",
      "model training. Jupyter notebooks provide a convenient tool for writing machine\n",
      "learning pipelines and interactively observing outputs, however, maintaining\n",
      "Jupyter notebooks, e.g., to add new features or fix bugs, can be challenging\n",
      "due to the length and complexity of the notebooks. Moreover, there is no\n",
      "existing benchmark related to developer edits on Jupyter notebooks. To address\n",
      "this, we present the first dataset of 48,398 Jupyter notebook edits derived\n",
      "from 20,095 revisions of 792 machine learning repositories on GitHub, and\n",
      "perform the first study of the using LLMs to predict code edits in Jupyter\n",
      "notebooks. Our dataset captures granular details of cell-level and line-level\n",
      "modifications, offering a foundation for understanding real-world maintenance\n",
      "patterns in machine learning workflows. We observed that the edits on Jupyter\n",
      "notebooks are highly localized, with changes averaging only 166 lines of code\n",
      "in repositories. While larger models outperform smaller counterparts in code\n",
      "editing, all models have low accuracy on our dataset even after finetuning,\n",
      "demonstrating the complexity of real-world machine learning maintenance tasks.\n",
      "Our findings emphasize the critical role of contextual information in improving\n",
      "model performance and point toward promising avenues for advancing large\n",
      "language models' capabilities in engineering machine learning code.\n",
      "Published: 2025-01-16 18:55:38+00:00\n",
      "journal_ref: None\n",
      "ODOI: None\n",
      "Primary Category: cs.SE\n",
      "categories: cs.SE, cs.CL, cs.LG\n",
      "PDF url: http://arxiv.org/pdf/2501.09745v1\n",
      "arxiv url: http://arxiv.org/abs/2501.09745v1\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Quantum Computing\n",
      "Answer: \n",
      "\u001b[0m> Running step d8031431-0fab-47bb-bae6-7a3ec12d83b3. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I cannot find any relevant papers related to Quantum Computing in the provided context. I will now search for recent papers on Quantum Computing from arXiv.\n",
      "Action: fetch_from_arxiv\n",
      "Action Input: {'title': 'Quantum Computing', 'paper_count': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [{'title': 'Can effective descriptions of bosonic systems be considered complete?', 'summary': 'Bosonic statistics give rise to remarkable phenomena, from the Hong-Ou-Mandel\\neffect to Bose-Einstein condensation, with applications spanning fundamental\\nscience to quantum technologies. Modeling bosonic systems relies heavily on\\neffective descriptions: typical examples include truncating their\\ninfinite-dimensional state space and restricting their dynamics to a simple\\nclass of Hamiltonians, such as polynomials of canonical operators, which are\\nused to define quantum computing over bosonic modes. However, many natural\\nbosonic Hamiltonians do not belong to this simple class, and some quantum\\neffects harnessed by bosonic computers inherently require infinite-dimensional\\nspaces, questioning the validity of such effective descriptions of bosonic\\nsystems. How can we trust results obtained with such simplifying assumptions to\\ncapture real effects?\\n  Driven by the increasing importance of bosonic systems for quantum\\ntechnologies, we solve this outstanding problem by showing that these effective\\ndescriptions do in fact capture the relevant physics of bosonic systems. Our\\ntechnical contribution is twofold: firstly, we prove that any physical, bosonic\\nunitary evolution can be strongly approximated by a finite-dimensional unitary\\nevolution; secondly, we show that any finite-dimensional unitary evolution can\\nbe generated exactly by a bosonic Hamiltonian that is a polynomial of canonical\\noperators. Beyond their fundamental significance, our results have implications\\nfor classical and quantum simulations of bosonic systems, they provide\\nuniversal methods for engineering bosonic quantum states and Hamiltonians, they\\nshow that polynomial Hamiltonians do generate universal gate sets for quantum\\ncomputing over bosonic modes, and they lead to an infinite-dimensional\\nSolovay--Kitaev theorem.', 'published': datetime.datetime(2025, 1, 23, 17, 27, 54, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'quant-ph', 'categories': ['quant-ph'], 'authors': ['Francesco Arzani', 'Robert I. Booth', 'Ulysse Chabaud'], 'pdf_url': 'http://arxiv.org/pdf/2501.13857v1', 'arxiv_url': 'http://arxiv.org/abs/2501.13857v1'}, {'title': 'Rudraksh: A compact and lightweight post-quantum key-encapsulation mechanism', 'summary': 'Resource-constrained devices such as wireless sensors and Internet of Things\\n(IoT) devices have become ubiquitous in our digital ecosystem. These devices\\ngenerate and handle a major part of our digital data. However, due to the\\nimpending threat of quantum computers on our existing public-key cryptographic\\nschemes and the limited resources available on IoT devices, it is important to\\ndesign lightweight post-quantum cryptographic (PQC) schemes suitable for these\\ndevices. In this work, we explored the design space of learning with\\nerror-based PQC schemes to design a lightweight key-encapsulation mechanism\\n(KEM) suitable for resource-constrained devices. We have done a scrupulous and\\nextensive analysis and evaluation of different design elements, such as\\npolynomial size, field modulus structure, reduction algorithm, and secret and\\nerror distribution of an LWE-based KEM. Our explorations led to the proposal of\\na lightweight PQC-KEM, Rudraksh, without compromising security. Our scheme\\nprovides security against chosen ciphertext attacks (CCA) with more than 100\\nbits of Core-SVP post-quantum security and belongs to the NIST-level-I security\\ncategory (provide security at least as much as AES-128). We have also shown how\\nASCON can be used for lightweight pseudo-random number generation and hash\\nfunction in the lattice-based KEMs instead of the widely used Keccak for\\nlightweight design. Our FPGA results show that Rudraksh currently requires the\\nleast area among the PQC KEMs of similar security. Our implementation of\\nRudraksh provides a $\\\\sim3\\\\times$ improvement in terms of the area requirement\\ncompared to the state-of-the-art area-optimized implementation of Kyber, can\\noperate at $63\\\\%$-$76\\\\%$ higher frequency with respect to high-throughput\\nKyber, and improves time-area-product $\\\\sim2\\\\times$ compared to the\\nstate-of-the-art compact implementation of Kyber published in HPEC 2022.', 'published': datetime.datetime(2025, 1, 23, 16, 16, 23, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CR', 'categories': ['cs.CR'], 'authors': ['Suparna Kundu', 'Archisman Ghosh', 'Angshuman Karmakar', 'Shreyas Sen', 'Ingrid Verbauwhede'], 'pdf_url': 'http://arxiv.org/pdf/2501.13799v1', 'arxiv_url': 'http://arxiv.org/abs/2501.13799v1'}, {'title': 'Post-Quantum Stealth Address Protocols', 'summary': 'The Stealth Address Protocol (SAP) allows users to receive assets through\\nstealth addresses that are unlinkable to their stealth meta-addresses. The most\\nwidely used SAP, Dual-Key SAP (DKSAP), and the most performant SAP, Elliptic\\nCurve Pairing Dual-Key SAP (ECPDKSAP), are based on elliptic curve\\ncryptography, which is vulnerable to quantum attacks. These protocols depend on\\nthe elliptic curve discrete logarithm problem, which could be efficiently\\nsolved on a sufficiently powerful quantum computer using the Shor algorithm. In\\nthis paper three novel post-quantum SAPs based on lattice-based cryptography\\nare presented: LWE SAP, Ring-LWE SAP and Module-LWE SAP. These protocols\\nleverage Learning With Errors (LWE) problem to ensure quantum-resistant\\nprivacy. Among them, Module-LWE SAP, which is based on the Kyber key\\nencapsulation mechanism, achieves the best performance and outperforms ECPDKSAP\\nby approximately 66.8% in the scan time of the ephemeral public key registry.', 'published': datetime.datetime(2025, 1, 23, 15, 9, 49, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CR', 'categories': ['cs.CR'], 'authors': ['Marija Mikic', 'Mihajlo Srbakoski', 'Strahinja Praska'], 'pdf_url': 'http://arxiv.org/pdf/2501.13733v1', 'arxiv_url': 'http://arxiv.org/abs/2501.13733v1'}, {'title': 'Characterization and Optimization of Tunable Couplers via Adiabatic Control in Superconducting Circuits', 'summary': 'In the pursuit of scalable superconducting quantum computing, tunable\\ncouplers have emerged as a pivotal component, offering the flexibility required\\nfor complex quantum operations of high performance. In most current\\narchitectures of superconducting quantum chips, such couplers are not equipped\\nwith dedicated readout circuits to reduce complexity in both design and\\noperation. However, this strategy poses challenges in precise characterization,\\ncalibration, and control of the couplers. In this work, we develop a\\nhardware-efficient and robust technique based on adiabatic control to address\\nthe above issue. The critical ingredient of this technique is adiabatic swap\\n(aSWAP) operation between a tunable coupler and nearby qubits. Using this\\ntechnique, we have characterized and calibrated tunable couplers in our chips\\nand achieved straightforward and precise control over these couplers. For\\nexample, we have demonstrated the calibration and correction of the flux\\ndistortion of couplers. In addition, we have also expanded this technique to\\ntune the dispersive shift between a frequency-fixed qubit and its readout\\nresonator over a wide range.', 'published': datetime.datetime(2025, 1, 23, 13, 25, 55, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'quant-ph', 'categories': ['quant-ph'], 'authors': ['Xuan Zhang', 'Xu Zhang', 'Changling Chen', 'Kai Tang', 'Kangyuan Yi', 'Kai Luo', 'Zheshu Xie', 'Yuanzhen Chen', 'Tongxing Yan'], 'pdf_url': 'http://arxiv.org/pdf/2501.13646v1', 'arxiv_url': 'http://arxiv.org/abs/2501.13646v1'}, {'title': '(111) Si spin qubits constructed on L point of band structure', 'summary': '(001) Si spin qubits are being intensively studied because they have\\nstructures similar to that of CMOS devices currently being produced, and thus\\nhave the advantage of utilizing state-of-the-art miniaturization, integration,\\nand variation-reduction-technologies. However, there are still issues, such as\\nfurther improvement of relaxation and decoherence time, stabilization of\\nvalley-splitting control, and reduction of the variation caused by the\\nroughness of the interface. In this study, new measures are proposed to address\\nthese three issues. Instead of confining an electron to the minimum energy\\npoint $X_0$ of the conduction band along the band structure $\\\\Gamma-\\\\Delta-X$\\nin (001) Si crystals, we propose confining an electron to the L point along\\n$\\\\Gamma-\\\\Lambda-L$ in (111) Si crystals. At the $X_0$ point, the symmetry\\ncauses spin-orbit interaction to act on the electron, and the sixfold\\ndegeneracy is lifted into a fourfold and a twofold, and the valley-splitting of\\nthe twofold conflicts with the two-level system. In the symmetry of the $L$\\npoint, substantial spin polarization disappears, facilitating the reduction of\\nthe spin-orbit interaction, and the fourfold degeneracy is lifted to threefold\\nand single, and the single becomes ground state. The need to increase the\\nmagnitude of the valley-splitting is exempt, allowing the electron to be\\ncontrolled away from the interface, which is expected to reduce the variation\\ncaused by the roughness of the interface. Data on the confinement of an\\nelectron to the $L$ point and the control of fourfold degeneracy are needed,\\nand it is hoped that prototype silicon spin qubits constructed on (111) Si\\ncrystals will be developed and that the proposed device structure will help\\nimplement quantum computers based on Si devices.', 'published': datetime.datetime(2025, 1, 23, 10, 46, 35, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'quant-ph', 'categories': ['quant-ph', 'cond-mat.mes-hall', 'physics.app-ph'], 'authors': ['Takafumi Tokunaga', 'Hiromichi Nakazato'], 'pdf_url': 'http://arxiv.org/pdf/2501.13546v1', 'arxiv_url': 'http://arxiv.org/abs/2501.13546v1'}]\n",
      "\u001b[0m> Running step 6bc16cd3-5d25-4909-84d5-ec0fdcdb55ad. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have found several recent papers related to Quantum Computing from arXiv. Here are the details:\n",
      "\n",
      "1. **Title**: Can effective descriptions of bosonic systems be considered complete?\n",
      "   - **Authors**: Francesco Arzani, Robert I. Booth, Ulysse Chabaud\n",
      "   - **Summary**: This paper discusses the effective descriptions of bosonic systems and their implications for quantum technologies. It proves that any physical, bosonic unitary evolution can be approximated by a finite-dimensional unitary evolution and shows that polynomial Hamiltonians generate universal gate sets for quantum computing over bosonic modes.\n",
      "   - **Published**: 2025-01-23\n",
      "   - **Link**: [arXiv](http://arxiv.org/abs/2501.13857v1)\n",
      "\n",
      "2. **Title**: Rudraksh: A compact and lightweight post-quantum key-encapsulation mechanism\n",
      "   - **Authors**: Suparna Kundu, Archisman Ghosh, Angshuman Karmakar, Shreyas Sen, Ingrid Verbauwhede\n",
      "   - **Summary**: This work explores lightweight post-quantum cryptographic schemes suitable for resource-constrained devices, proposing a key-encapsulation mechanism that provides security against quantum attacks.\n",
      "   - **Published**: 2025-01-23\n",
      "   - **Link**: [arXiv](http://arxiv.org/abs/2501.13799v1)\n",
      "\n",
      "3. **Title**: Post-Quantum Stealth Address Protocols\n",
      "   - **Authors**: Marija Mikic, Mihajlo Srbakoski, Strahinja Praska\n",
      "   - **Summary**: This paper presents novel post-quantum stealth address protocols based on lattice-based cryptography, ensuring quantum-resistant privacy.\n",
      "   - **Published**: 2025-01-23\n",
      "   - **Link**: [arXiv](http://arxiv.org/abs/2501.13733v1)\n",
      "\n",
      "4. **Title**: Characterization and Optimization of Tunable Couplers via Adiabatic Control in Superconducting Circuits\n",
      "   - **Authors**: Xuan Zhang, Xu Zhang, Changling Chen, Kai Tang, Kangyuan Yi, Kai Luo, Zheshu Xie, Yuanzhen Chen, Tongxing Yan\n",
      "   - **Summary**: This work develops a technique based on adiabatic control for the characterization and calibration of tunable couplers in superconducting quantum circuits.\n",
      "   - **Published**: 2025-01-23\n",
      "   - **Link**: [arXiv](http://arxiv.org/abs/2501.13646v1)\n",
      "\n",
      "5. **Title**: (111) Si spin qubits constructed on L point of band structure\n",
      "   - **Authors**: Takafumi Tokunaga, Hiromichi Nakazato\n",
      "   - **Summary**: This study proposes new measures for improving the performance of (001) Si spin qubits by confining electrons to the L point in (111) Si crystals, addressing issues related to relaxation and decoherence time.\n",
      "   - **Published**: 2025-01-23\n",
      "   - **Link**: [arXiv](http://arxiv.org/abs/2501.13546v1)\n",
      "Answer: Here are some recent papers related to Quantum Computing. If you would like to download any of them, please let me know!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#we want toask abot a topic which is not in the database\n",
    "answer = agent.chat(query_template.format(topic= \"Quantum Computing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some recent papers related to Quantum Computing. If you would like to download any of them, please let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer = agent.chat(query_template.format(topic= \"Algebraic Topology\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Markdown(answer.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
